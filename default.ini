<<<<<<< HEAD

[audio]
sampling_rate = 44100
hop_length = 128
segment_length = 1024

[dataset]
datapath = [your_dataset_path]
test_dataset = test_audio
generate_test = True
check_audio = True
check_dataset = True
workspace = 
run_number = 0
total_frames = 

[VAE]
latent_dim = 256
n_units = 2048
kl_beta = 0.0001
device = cuda:0

[training]
epochs = 500
save_best_model_after = 80
learning_rate = 0.0001
batch_size = 131072
checkpoint_interval = 90
loss_reduction = mean # either mean for average loss, or sum for total loss, see torch.nn.MSEloss

[notes]
additional_notes = 

[extra]
normalize_examples = False
example_length = 10
plot_model = True

description = nospectral_workstation
start = 
end = 
time_elapsed = 
=======

[audio]
sampling_rate = 44100
hop_length = 512
segment_length = 1024

[dataset]
datapath = D:\kelse\03_Repositories\RAWAUDIOVAE_PROJECT\latent-timbre-synthesis-pytorch\dataset
test_dataset = test_audio
generate_test = True
check_audio = True
check_dataset = True
workspace = 
run_number = 0
total_frames = 

[VAE]
latent_dim = 256
n_units = 2048
kl_beta = 0.0001
device = cuda:0
lstm_hidden_size = 256

[training]
epochs = 5
save_best_model_after = 1
learning_rate = 0.0001
batch_size = 512
checkpoint_interval = 1

[notes]
additional_notes = vanilla run,10epochs, my voice data, 2025-02-21

[extra]
normalize_examples = False
example_length = 10
plot_model = True

description = POC_rawVAE_KCLib_10e_workstation
start = 
end = 
time_elapsed = 
>>>>>>> windowing-repo/main
