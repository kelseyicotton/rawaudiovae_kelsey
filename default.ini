
[audio]
sampling_rate = 44100
hop_length = 128
segment_length = 1024

[dataset]
datapath = [your_dataset_path]
test_dataset = test_audio
generate_test = True
check_audio = True
check_dataset = True
workspace = 
run_number = 0
total_frames = 

[VAE]
latent_dim = 256
n_units = 2048
kl_beta = 0.0001
device = cuda:0

[training]
epochs = 500
total_num_frames = 154371400000 # total number of frames in mid-size dataset 3087428 * 500 epochs * 100 since now we have a dataset with 50 times more audio files
save_best_model_after = 80
learning_rate = 0.0001
batch_size = 131072
checkpoint_interval = 90
loss_reduction = mean # either mean for average loss, or sum for total loss, see torch.nn.MSEloss

[notes]
additional_notes = 

[extra]
normalize_examples = False
example_length = 10
plot_model = True

description = nospectral_workstation
start = 
end = 
time_elapsed = 
